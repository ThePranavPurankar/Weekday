{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed5dac",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#000;font-size:30px;background-color:#15C6B4;width:100%;height:30px;text-align:center\">Weekday-Text Classification</h1>\n",
    "\n",
    "<p>\n",
    "<h4 style=\"color:#ff6871;\">Last edited:-<span style=\"color:#808080\"> Pranav Purankar 28-Oct 2023</span></h4>\n",
    "<h4 style=\"color:#ff6871;\">Team:-<span style=\"color:#808080\"> Product Management</span></h4>\n",
    "<h4 style=\"color:#ff6871;\">Details:-<span style=\"color:#808080;line-height:18pt\"> This file contains a pre-processed data. This data can be useful for classifying a particular candidate; to indetify which industry segment he/she/they belongs to. Kindly refer this GitBook to get an in-depth overview of the project:- <a>URL(http:www.google.com)</a></span></h4>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b81dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from ydata_profiling import ProfileReport\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# import os\n",
    "# import spacy\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377e4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Enrich_Company_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027ff13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb11904bccb48059648355b85f06843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59f29bd66aa4ffca62647cf9a626cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b4e7e87e264a8daf2feb8e2b3ae589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a32e27e1994b92b48117b670ff3e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary of the existing data\n",
    "prof=ProfileReport(df)\n",
    "prof.to_file(output_file='company_data_summary.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "846bab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Website</th>\n",
       "      <th>Slug</th>\n",
       "      <th>Country</th>\n",
       "      <th>Enrich Company</th>\n",
       "      <th>Employee Count</th>\n",
       "      <th>Company URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>autonomous checkout technology platform retail...</td>\n",
       "      <td>brysk.com</td>\n",
       "      <td>brysk</td>\n",
       "      <td>US</td>\n",
       "      <td>Brysk</td>\n",
       "      <td>17</td>\n",
       "      <td>https://linkedin.com/company/niflr\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>kognitiv redefines loyalty helping brands secu...</td>\n",
       "      <td>kognitiv.com</td>\n",
       "      <td>kognitiv-corporation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Kognitiv Corporation</td>\n",
       "      <td>355</td>\n",
       "      <td>http://www.linkedin.com/company/kognitiv-corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>hono began 2008 pioneering hrtech solutions em...</td>\n",
       "      <td>hono.ai</td>\n",
       "      <td>connectwithhono</td>\n",
       "      <td>IN</td>\n",
       "      <td>HONO</td>\n",
       "      <td>219</td>\n",
       "      <td>http://linkedin.com/company/connectwithhono\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>mool established simple purpose advise worlds ...</td>\n",
       "      <td>mool.one</td>\n",
       "      <td>moolmantra</td>\n",
       "      <td>IN</td>\n",
       "      <td>Mool</td>\n",
       "      <td>28</td>\n",
       "      <td>http://linkedin.com/company/moolmantra/\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>missing</td>\n",
       "      <td>leap.club</td>\n",
       "      <td>leapclub</td>\n",
       "      <td>IN</td>\n",
       "      <td>leap.club</td>\n",
       "      <td>150</td>\n",
       "      <td>https://linkedin.com/company/leapclub\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>axessai product hardmate inc delaware c corpor...</td>\n",
       "      <td>axess.ai</td>\n",
       "      <td>axess-ai</td>\n",
       "      <td>US</td>\n",
       "      <td>axessAI</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.linkedin.com/company/axess-ai/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>gromo mission increase accessibility financial...</td>\n",
       "      <td>gromo.in</td>\n",
       "      <td>gromofintech</td>\n",
       "      <td>IN</td>\n",
       "      <td>GroMo</td>\n",
       "      <td>467</td>\n",
       "      <td>https://linkedin.com/company/gromofintech/about\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>cbazaar among earliest ecommerce companies ind...</td>\n",
       "      <td>cbazaar.com</td>\n",
       "      <td>cbazaar</td>\n",
       "      <td>IN</td>\n",
       "      <td>Cbazaar.com</td>\n",
       "      <td>240</td>\n",
       "      <td>http://linkedin.com/company/cbazaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>refrens place independant freelancers b2b serv...</td>\n",
       "      <td>refrens.com</td>\n",
       "      <td>refrens</td>\n",
       "      <td>IN</td>\n",
       "      <td>Refrens</td>\n",
       "      <td>38</td>\n",
       "      <td>https://linkedin.com/company/refrens\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>almamapper education employment oriented netwo...</td>\n",
       "      <td>almamapper.com</td>\n",
       "      <td>almamapper-technologies-pvt--ltd-</td>\n",
       "      <td>IN</td>\n",
       "      <td>AlmaMapper Technologies</td>\n",
       "      <td>11</td>\n",
       "      <td>http://linkedin.com/company/almamapper-technol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description         Website  \\\n",
       "620  autonomous checkout technology platform retail...       brysk.com   \n",
       "477  kognitiv redefines loyalty helping brands secu...    kognitiv.com   \n",
       "399  hono began 2008 pioneering hrtech solutions em...         hono.ai   \n",
       "573  mool established simple purpose advise worlds ...        mool.one   \n",
       "496                                            missing       leap.club   \n",
       "..                                                 ...             ...   \n",
       "79   axessai product hardmate inc delaware c corpor...        axess.ai   \n",
       "360  gromo mission increase accessibility financial...        gromo.in   \n",
       "128  cbazaar among earliest ecommerce companies ind...     cbazaar.com   \n",
       "760  refrens place independant freelancers b2b serv...     refrens.com   \n",
       "40   almamapper education employment oriented netwo...  almamapper.com   \n",
       "\n",
       "                                  Slug Country           Enrich Company  \\\n",
       "620                              brysk      US                    Brysk   \n",
       "477               kognitiv-corporation      CA     Kognitiv Corporation   \n",
       "399                    connectwithhono      IN                     HONO   \n",
       "573                         moolmantra      IN                     Mool   \n",
       "496                           leapclub      IN                leap.club   \n",
       "..                                 ...     ...                      ...   \n",
       "79                            axess-ai      US                  axessAI   \n",
       "360                       gromofintech      IN                    GroMo   \n",
       "128                            cbazaar      IN              Cbazaar.com   \n",
       "760                            refrens      IN                  Refrens   \n",
       "40   almamapper-technologies-pvt--ltd-      IN  AlmaMapper Technologies   \n",
       "\n",
       "     Employee Count                                        Company URL  \n",
       "620              17               https://linkedin.com/company/niflr\\r  \n",
       "477             355  http://www.linkedin.com/company/kognitiv-corpo...  \n",
       "399             219      http://linkedin.com/company/connectwithhono\\r  \n",
       "573              28          http://linkedin.com/company/moolmantra/\\r  \n",
       "496             150            https://linkedin.com/company/leapclub\\r  \n",
       "..              ...                                                ...  \n",
       "79                1         https://www.linkedin.com/company/axess-ai/  \n",
       "360             467  https://linkedin.com/company/gromofintech/about\\r  \n",
       "128             240                http://linkedin.com/company/cbazaar  \n",
       "760              38             https://linkedin.com/company/refrens\\r  \n",
       "40               11  http://linkedin.com/company/almamapper-technol...  \n",
       "\n",
       "[782 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27984b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining columns, filling Na values with relevant data, dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f751a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Org Id','Created At','Size','Locality','Updated At'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d01106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employee Count']=df['Employee Count'].fillna(0).apply(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875c02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['New_Industry_filled_by_specialities']=df['Industry'].fillna(df['Specialities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8058b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['concatenate']=df['New_Industry_filled_by_specialities'] + \", \" + df['Specialities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d1157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['concatenate']=df['concatenate'].fillna(df['New_Industry_filled_by_specialities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2732d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'concatenate':'Industry_Specialities'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763cef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description']=df['Description'] + \" \" + df[\"Industry_Specialities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8cbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Industry','Specialities','New_Industry_filled_by_specialities','Industry_Specialities'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677ab3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 783 entries, 0 to 782\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Description     689 non-null    object\n",
      " 1   Website         765 non-null    object\n",
      " 2   Slug            782 non-null    object\n",
      " 3   Country         782 non-null    object\n",
      " 4   Enrich Company  782 non-null    object\n",
      " 5   Employee Count  783 non-null    int32 \n",
      " 6   Company URL     782 non-null    object\n",
      "dtypes: int32(1), object(6)\n",
      "memory usage: 39.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce49ff64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStoring NaN values in the description, every bit of information is essential.\\nThis is vital column for our whole analysis process.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Storing NaN values in the description, every bit of information is essential.\n",
    "This is vital column for our whole analysis process.\n",
    "'''\n",
    "# nan_values = df[df['Description'].isna()]\n",
    "# df=pd.DataFrame(nan_values)\n",
    "# df.to_csv('nan_values.csv',index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a23029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description']=df['Description'].fillna('Missing')\n",
    "df['Website']=df['Website'].fillna('nourl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb9ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22284fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 782 entries, 0 to 781\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Description     782 non-null    object\n",
      " 1   Website         782 non-null    object\n",
      " 2   Slug            782 non-null    object\n",
      " 3   Country         782 non-null    object\n",
      " 4   Enrich Company  782 non-null    object\n",
      " 5   Employee Count  782 non-null    int32 \n",
      " 6   Company URL     782 non-null    object\n",
      "dtypes: int32(1), object(6)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5661db",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#ffb700\"> Text Pre-processing </h2>\n",
    "<p style=\"color:#808080;font-size:20px\"> 1. Lowercasing letters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fef4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26545/4094036355.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Description']=df['Description'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237    an indo-norwegian cloud-software company on a ...\n",
       "335    getfocus (focus analytics pvt. ltd.) is an exc...\n",
       "495                                              missing\n",
       "254    checkout financing, lending and payments platf...\n",
       "290    filo is the worlds only live instant tutoring ...\n",
       "                             ...                        \n",
       "361    hey!\\n\\ngrow indigo was established in 2018 by...\n",
       "373    haikujam is a mobile game that promotes self-c...\n",
       "183    credihealth is an online solution to all your ...\n",
       "419    a leading future tech-based professional educa...\n",
       "202    dass scientific research labs private limited ...\n",
       "Name: Description, Length: 782, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description']=df['Description'].str.lower()\n",
    "df['Description'].sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c6669",
   "metadata": {},
   "source": [
    "<p style=\"color:#808080;font-size:20px\"> 2. Removing Punctuation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52f09dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    punctuations=string.punctuation\n",
    "    return text.translate(str.maketrans('','',punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a23f3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26545/199114757.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Description']=df['Description'].apply(lambda x: remove_punctuations(x))\n"
     ]
    }
   ],
   "source": [
    "df['Description']=df['Description'].apply(lambda x: remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1de387a",
   "metadata": {},
   "source": [
    "<p style=\"color:#808080;font-size:20px\"> 3. Removing Stopwords</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c38cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f6b248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS=set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e27c0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26545/3129844413.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Description']=df['Description'].apply(lambda x: remove_stopwords(x))\n"
     ]
    }
   ],
   "source": [
    "df['Description']=df['Description'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94d761",
   "metadata": {},
   "source": [
    "<p style=\"color:#808080;font-size:20px\"> 4. Removing Special Characters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edf81044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spl_chars(text):\n",
    "    text=re.sub('[^a-zA-Z0-9]',\" \",text)\n",
    "    text=re.sub('\\s+',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9e71531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26545/2318416937.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Description']=df['Description'].apply(lambda x: remove_spl_chars(x))\n"
     ]
    }
   ],
   "source": [
    "df['Description']=df['Description'].apply(lambda x: remove_spl_chars(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd429e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#ffb700\"> Data Annotation </h2>\n",
    "<p style=\"color:#808080;font-size:20px\"> 1. Each row as a text file</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6134342",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df['Description']\n",
    "file = 'file{}.txt'\n",
    "\n",
    "n = 0 # to number the files\n",
    "for row in d.items():\n",
    "    with open(file.format(n), 'w') as f:\n",
    "        f.write(str(row))\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e806a",
   "metadata": {},
   "source": [
    "<p style=\"color:#808080;font-size:20px\"> 2. Labelled data (doccano output)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c56235",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26545/1715649116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m                 \u001b[0mdata_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             )\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "df_json=pd.read_json('all.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_json['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e3768",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red\"> Why do you stop here? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e625b5a",
   "metadata": {},
   "source": [
    "<a href=\"https://www.freeiconspng.com/img/27213\" title=\"Image from freeiconspng.com\"><img src=\"https://www.freeiconspng.com/uploads/stop-sign-png-8.png\" width=\"350\" alt=\"Png Clipart Collection Stop Sign\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad963c",
   "metadata": {},
   "source": [
    "<p style=\"color:#2F4F4F;font-size:20px\"> Below are some reasons as why you should stop here:</p>\n",
    "<ul>\n",
    "    <li style=\"font-size:18px;color:#2F4F4F;margin:0 0 10px 0\"> A data annotation tool like doccano offers manual data annotation only. To make this process automatic we need to use cloud based NLP API services or paid tool like UbiAI, label studio, prodigy etc. I tried UbiAI, label studio both are good but not a perfect one.</li>\n",
    "    <li style=\"font-size:18px;color:#2F4F4F;margin:0 0 10px 0\"> Do we have existing ML/DL model? If yes then, we need to fine tune our pre-processing as per the existing pipeline. If we don't have any existing pipeline for NLP tasks then need to think about complete architecture.</li>\n",
    "    <li style=\"font-size:18px;color:#2F4F4F;margin:0 0 10px 0\"> The reason I'm submitting this assignment too late because, \"Don't join a company to get your next paycheck.\" I've explain this in the video (Why should we hire you?) hint: Product Management + Data Analysis (ML) = this combination has tremendous potential to deliver a habit forming product (no matter whether it's B2B or B2C segment)</li>    \n",
    "</ul>\n",
    "<h1 style=\"color:#ff6871;text-align:center\"> Thank You!</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee39670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c59f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
